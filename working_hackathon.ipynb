{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit plotly pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPpyE_ePkqPc",
        "outputId": "a33a48eb-df46-40a2-86f6-bd7e5375dcba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.52.2-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.5.0 streamlit-1.52.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile churn_pred.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import warnings\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# OPENROUTER CONFIGURATION WITH API KEY ROTATION\n",
        "# ==============================================================================\n",
        "\n",
        "class OpenRouterConfig:\n",
        "    \"\"\"Configuration for OpenRouter with API key rotation\n",
        "\n",
        "    Supports up to 3 API keys with automatic rotation on rate limits or errors.\n",
        "    Get free API keys from: https://openrouter.ai/keys\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_keys=None):\n",
        "        # Support for 3 API keys with rotation\n",
        "        if api_keys is None:\n",
        "            api_keys = [\n",
        "                os.environ.get('OPENROUTER_API_KEY_1'),\n",
        "                os.environ.get('OPENROUTER_API_KEY_2'),\n",
        "                os.environ.get('OPENROUTER_API_KEY_3')\n",
        "            ]\n",
        "\n",
        "        # Filter out None values\n",
        "        self.api_keys = [key for key in api_keys if key]\n",
        "\n",
        "        if not self.api_keys:\n",
        "            raise ValueError(\"At least one OpenRouter API key must be provided\")\n",
        "\n",
        "        self.current_key_index = 0\n",
        "        self.api_base = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "        # Using free OpenRouter models (fallback chain)\n",
        "        # These models don't require privacy policy configuration\n",
        "        self.models = [\n",
        "            'meta-llama/llama-3.2-3b-instruct:free',  # Primary: Fast and free\n",
        "            'google/gemini-flash-1.5:free',           # Fallback 1: Google's free model\n",
        "            'nousresearch/hermes-3-llama-3.1-405b:free'  # Fallback 2: Powerful free model\n",
        "        ]\n",
        "        self.current_model_index = 0\n",
        "        self.model_name = self.models[self.current_model_index]\n",
        "\n",
        "        # Generation config\n",
        "        self.temperature = 0.7\n",
        "        self.max_tokens = 2048\n",
        "        self.top_p = 0.95\n",
        "\n",
        "        print(f\"‚úì OpenRouter configured with {len(self.api_keys)} API key(s)\")\n",
        "        print(f\"‚úì Using model: {self.model_name} (with {len(self.models)} fallback models)\")\n",
        "\n",
        "    def get_current_api_key(self):\n",
        "        \"\"\"Get the current API key\"\"\"\n",
        "        return self.api_keys[self.current_key_index]\n",
        "\n",
        "    def rotate_api_key(self):\n",
        "        \"\"\"Rotate to the next API key\"\"\"\n",
        "        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)\n",
        "        print(f\"üîÑ Rotated to API key #{self.current_key_index + 1}\")\n",
        "\n",
        "    def rotate_model(self):\n",
        "        \"\"\"Rotate to the next available model\"\"\"\n",
        "        self.current_model_index = (self.current_model_index + 1) % len(self.models)\n",
        "        self.model_name = self.models[self.current_model_index]\n",
        "        print(f\"üîÑ Switched to model: {self.model_name}\")\n",
        "\n",
        "    def make_request(self, messages, system_message=None, retry_count=0, model_retry_count=0):\n",
        "        \"\"\"Make a request to OpenRouter with automatic key and model rotation on failure\"\"\"\n",
        "\n",
        "        if retry_count >= len(self.api_keys) * 2:  # Try each key twice\n",
        "            if model_retry_count >= len(self.models):\n",
        "                raise Exception(\"All API keys and models exhausted or unavailable\")\n",
        "            # Try next model\n",
        "            self.rotate_model()\n",
        "            return self.make_request(messages, system_message, 0, model_retry_count + 1)\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.get_current_api_key()}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"HTTP-Referer\": \"https://github.com/yourusername/ai-personalization\",  # Optional\n",
        "            \"X-Title\": \"AI Hyper-Personalization Engine\"  # Optional\n",
        "        }\n",
        "\n",
        "        # Prepare messages with system message if provided\n",
        "        formatted_messages = []\n",
        "        if system_message:\n",
        "            formatted_messages.append({\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_message\n",
        "            })\n",
        "        formatted_messages.extend(messages)\n",
        "\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": formatted_messages,\n",
        "            \"temperature\": self.temperature,\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"top_p\": self.top_p\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                f\"{self.api_base}/chat/completions\",\n",
        "                headers=headers,\n",
        "                json=payload,\n",
        "                timeout=30\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 404:  # Model not available or privacy policy issue\n",
        "                error_msg = response.json().get('error', {}).get('message', 'Unknown error')\n",
        "                print(f\"‚ö† Model unavailable: {error_msg}\")\n",
        "                # Try next model immediately\n",
        "                if model_retry_count < len(self.models) - 1:\n",
        "                    self.rotate_model()\n",
        "                    time.sleep(0.5)\n",
        "                    return self.make_request(messages, system_message, 0, model_retry_count + 1)\n",
        "                else:\n",
        "                    raise Exception(f\"All models unavailable. Error: {error_msg}\")\n",
        "            elif response.status_code == 429:  # Rate limit\n",
        "                print(f\"‚ö† Rate limit hit on API key #{self.current_key_index + 1}\")\n",
        "                self.rotate_api_key()\n",
        "                time.sleep(1)\n",
        "                return self.make_request(messages, system_message, retry_count + 1, model_retry_count)\n",
        "            elif response.status_code == 401:  # Invalid key\n",
        "                print(f\"‚ö† Invalid API key #{self.current_key_index + 1}\")\n",
        "                self.rotate_api_key()\n",
        "                return self.make_request(messages, system_message, retry_count + 1, model_retry_count)\n",
        "            else:\n",
        "                print(f\"‚ö† Error {response.status_code}: {response.text}\")\n",
        "                self.rotate_api_key()\n",
        "                time.sleep(1)\n",
        "                return self.make_request(messages, system_message, retry_count + 1, model_retry_count)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† Request failed: {e}\")\n",
        "            if retry_count < len(self.api_keys) - 1:\n",
        "                self.rotate_api_key()\n",
        "                time.sleep(1)\n",
        "                return self.make_request(messages, system_message, retry_count + 1, model_retry_count)\n",
        "            elif model_retry_count < len(self.models) - 1:\n",
        "                # Try next model\n",
        "                self.rotate_model()\n",
        "                time.sleep(1)\n",
        "                return self.make_request(messages, system_message, 0, model_retry_count + 1)\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# AI AGENT WRAPPER FOR OPENROUTER\n",
        "# ==============================================================================\n",
        "\n",
        "class AIAgent:\n",
        "    \"\"\"Wrapper for OpenRouter to simulate agent behavior\"\"\"\n",
        "\n",
        "    def __init__(self, name: str, system_message: str, config: OpenRouterConfig):\n",
        "        self.name = name\n",
        "        self.system_message = system_message\n",
        "        self.config = config\n",
        "        self.chat_history = []\n",
        "\n",
        "    def analyze(self, prompt: str) -> str:\n",
        "        \"\"\"Send a prompt to the agent and get response\"\"\"\n",
        "        try:\n",
        "            # Add user message to history\n",
        "            self.chat_history.append({\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            })\n",
        "\n",
        "            # Make request to OpenRouter\n",
        "            response = self.config.make_request(\n",
        "                messages=self.chat_history,\n",
        "                system_message=self.system_message\n",
        "            )\n",
        "\n",
        "            # Extract response text\n",
        "            assistant_message = response['choices'][0]['message']['content']\n",
        "\n",
        "            # Add assistant response to history\n",
        "            self.chat_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": assistant_message\n",
        "            })\n",
        "\n",
        "            return assistant_message\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† Error in {self.name}: {e}\")\n",
        "            return f\"Analysis unavailable due to error: {str(e)}\"\n",
        "\n",
        "    def reset_chat(self):\n",
        "        \"\"\"Reset the chat history\"\"\"\n",
        "        self.chat_history = []\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# AI-POWERED HYPER-PERSONALIZATION ENGINE\n",
        "# ==============================================================================\n",
        "\n",
        "class HyperPersonalizationEngine:\n",
        "    \"\"\"\n",
        "    AI-First Individual-Centric Hyper-Personalization & Churn Intelligence Platform\n",
        "\n",
        "    This system creates individual customer profiles (not personas) and uses AI agents\n",
        "    to continuously analyze behavior, predict intent, and generate personalized actions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_path, use_ai_agents=True, api_keys=None):\n",
        "        self.data_path = data_path\n",
        "        self.df = None\n",
        "        self.customer_profiles = {}  # Individual customer intelligence\n",
        "        self.ml_models = {}\n",
        "        self.scaler = StandardScaler()\n",
        "        self.use_ai = use_ai_agents\n",
        "\n",
        "        # Initialize AI agents with OpenRouter\n",
        "        if self.use_ai:\n",
        "            try:\n",
        "                self.config = OpenRouterConfig(api_keys=api_keys)\n",
        "                self.setup_ai_agents()\n",
        "                print(\"‚úì AI-First Personalization Engine Initialized (OpenRouter)\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö† AI agents unavailable: {e}\")\n",
        "                self.use_ai = False\n",
        "\n",
        "    def setup_ai_agents(self):\n",
        "        \"\"\"Setup specialized AI agents for hyper-personalization\"\"\"\n",
        "\n",
        "        # Intent Prediction Agent\n",
        "        self.intent_agent = AIAgent(\n",
        "            name=\"IntentPredictor\",\n",
        "            system_message=\"\"\"You are an AI that predicts customer intent and next actions.\n",
        "\n",
        "            Analyze customer behavior patterns and predict:\n",
        "            1. What the customer is likely to do next (upgrade, downgrade, churn, stay)\n",
        "            2. Why they might take that action (pain points, satisfaction drivers)\n",
        "            3. When they're most likely to act (urgency signals)\n",
        "            4. What offer would resonate most with this specific individual\n",
        "\n",
        "            Provide JSON format responses with specific predictions and confidence scores.\n",
        "            Focus on individual-level insights, not generic personas.\"\"\",\n",
        "            config=self.config\n",
        "        )\n",
        "\n",
        "        # Propensity Scoring Agent\n",
        "        self.propensity_agent = AIAgent(\n",
        "            name=\"PropensityScorer\",\n",
        "            system_message=\"\"\"You are an AI that calculates purchase/upsell propensity.\n",
        "\n",
        "            For each customer, analyze:\n",
        "            1. Likelihood to purchase additional services (0-100%)\n",
        "            2. Which specific products/services they'd buy\n",
        "            3. Optimal pricing strategy for this individual\n",
        "            4. Best time/channel to make the offer\n",
        "            5. Predicted revenue impact\n",
        "\n",
        "            Provide actionable propensity scores with specific product recommendations.\n",
        "            Tailor everything to the individual customer's context.\"\"\",\n",
        "            config=self.config\n",
        "        )\n",
        "\n",
        "        # Churn Prevention Agent\n",
        "        self.churn_agent = AIAgent(\n",
        "            name=\"ChurnPreventer\",\n",
        "            system_message=\"\"\"You are an AI that predicts and prevents customer churn.\n",
        "\n",
        "            For each at-risk customer:\n",
        "            1. Identify specific churn risk factors for THIS customer\n",
        "            2. Predict churn probability and timeline\n",
        "            3. Generate personalized retention offers\n",
        "            4. Recommend proactive interventions\n",
        "            5. Calculate customer lifetime value at risk\n",
        "\n",
        "            Create individual retention strategies, not generic campaigns.\n",
        "            Focus on preventing churn before it happens.\"\"\",\n",
        "            config=self.config\n",
        "        )\n",
        "\n",
        "        # Personalization Orchestrator\n",
        "        self.orchestrator_agent = AIAgent(\n",
        "            name=\"PersonalizationOrchestrator\",\n",
        "            system_message=\"\"\"You are an AI that orchestrates personalized customer experiences.\n",
        "\n",
        "            Synthesize insights from intent, propensity, and churn predictions to:\n",
        "            1. Create a unified personalization strategy for each customer\n",
        "            2. Prioritize actions (retain vs upsell vs cross-sell vs nurture)\n",
        "            3. Generate personalized messaging and offers\n",
        "            4. Recommend optimal timing and channels\n",
        "            5. Predict overall business impact\n",
        "\n",
        "            Create real-time, adaptive strategies for individual customers.\n",
        "            Balance business goals with customer experience.\"\"\",\n",
        "            config=self.config\n",
        "        )\n",
        "\n",
        "    def load_and_prepare_data(self):\n",
        "        \"\"\"Load data and create individual customer profiles\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"LOADING CUSTOMER DATA & CREATING INDIVIDUAL PROFILES\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Load data\n",
        "        self.df = pd.read_csv(self.data_path)\n",
        "        print(f\"‚úì Loaded {len(self.df)} customers\")\n",
        "\n",
        "        # Store original customer IDs\n",
        "        if 'customerID' in self.df.columns:\n",
        "            self.customer_ids = self.df['customerID'].copy()\n",
        "            self.df_with_ids = self.df.copy()\n",
        "            self.df = self.df.drop(['customerID'], axis=1)\n",
        "\n",
        "        # Preprocess\n",
        "        self.df['TotalCharges'] = pd.to_numeric(self.df['TotalCharges'], errors='coerce')\n",
        "        self.df.dropna(inplace=True)\n",
        "        self.df[\"SeniorCitizen\"] = self.df[\"SeniorCitizen\"].map({0: \"No\", 1: \"Yes\"})\n",
        "\n",
        "        # Encode categorical variables\n",
        "        le = LabelEncoder()\n",
        "        for col in self.df.columns:\n",
        "            if self.df[col].dtype == 'object':\n",
        "                self.df[col] = le.fit_transform(self.df[col])\n",
        "\n",
        "        print(f\"‚úì Preprocessed data: {self.df.shape}\")\n",
        "\n",
        "        # Create individual profiles for each customer\n",
        "        print(\"\\nüìä Creating individual customer intelligence profiles...\")\n",
        "        self.create_customer_profiles()\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def create_customer_profiles(self):\n",
        "        \"\"\"Create detailed individual profiles for each customer (not personas)\"\"\"\n",
        "        print(f\"Creating {len(self.df)} individual customer profiles...\")\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            customer_id = self.customer_ids.iloc[idx] if hasattr(self, 'customer_ids') else f\"CUST_{idx}\"\n",
        "\n",
        "            # Create individual profile\n",
        "            profile = {\n",
        "                'customer_id': customer_id,\n",
        "                'features': row.to_dict(),\n",
        "                'segment': None,  # Will be assigned by clustering\n",
        "                'churn_risk': None,\n",
        "                'churn_probability': None,\n",
        "                'propensity_scores': {},\n",
        "                'predicted_intent': None,\n",
        "                'personalized_strategy': None,\n",
        "                'lifetime_value': None,\n",
        "                'risk_factors': [],\n",
        "                'opportunities': [],\n",
        "                'next_best_actions': [],\n",
        "                'created_at': datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            self.customer_profiles[customer_id] = profile\n",
        "\n",
        "        print(f\"‚úì Created {len(self.customer_profiles)} individual customer profiles\")\n",
        "\n",
        "    def build_ml_foundation(self):\n",
        "        \"\"\"Build ML models for predictions (foundation for AI agents)\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"BUILDING ML PREDICTION MODELS\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        X = self.df.drop(columns=['Churn'])\n",
        "        y = self.df['Churn'].values\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.3, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "        X_train[num_cols] = self.scaler.fit_transform(X_train[num_cols])\n",
        "        X_test[num_cols] = self.scaler.transform(X_test[num_cols])\n",
        "\n",
        "        # Train churn prediction model\n",
        "        print(\"\\n1. Training Churn Prediction Model...\")\n",
        "        churn_model = GradientBoostingClassifier(random_state=42, n_estimators=100)\n",
        "        churn_model.fit(X_train, y_train)\n",
        "        accuracy = churn_model.score(X_test, y_test)\n",
        "        print(f\"   ‚úì Churn Model Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "        # Train propensity models (simulate multiple product propensities)\n",
        "        print(\"\\n2. Training Propensity Models...\")\n",
        "        propensity_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "        propensity_model.fit(X_train, y_train)\n",
        "        print(f\"   ‚úì Propensity Models Trained\")\n",
        "\n",
        "        # Customer segmentation (micro-segments, not broad personas)\n",
        "        print(\"\\n3. Creating Micro-Segments...\")\n",
        "        kmeans = KMeans(n_clusters=20, random_state=42)  # 20 micro-segments\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        segments = kmeans.fit_predict(X_scaled)\n",
        "        print(f\"   ‚úì Created 20 micro-segments (not personas)\")\n",
        "\n",
        "        self.ml_models = {\n",
        "            'churn': churn_model,\n",
        "            'propensity': propensity_model,\n",
        "            'segmentation': kmeans,\n",
        "            'X_scaled': X_scaled\n",
        "        }\n",
        "\n",
        "        return self.ml_models\n",
        "\n",
        "    def enrich_profiles_with_predictions(self):\n",
        "        \"\"\"Enrich individual profiles with ML predictions\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ENRICHING INDIVIDUAL PROFILES WITH PREDICTIONS\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        X = self.df.drop(columns=['Churn'])\n",
        "        X_scaled = self.ml_models['X_scaled']\n",
        "\n",
        "        for idx, (customer_id, profile) in enumerate(self.customer_profiles.items()):\n",
        "            # Get predictions for this individual\n",
        "            customer_features = X.iloc[idx:idx+1]\n",
        "            customer_scaled = X_scaled[idx:idx+1]\n",
        "\n",
        "            # Churn prediction\n",
        "            churn_prob = self.ml_models['churn'].predict_proba(customer_features)[0][1]\n",
        "            churn_risk = 'High' if churn_prob > 0.7 else 'Medium' if churn_prob > 0.4 else 'Low'\n",
        "\n",
        "            # Propensity scores (simulate for different products)\n",
        "            base_propensity = self.ml_models['propensity'].predict_proba(customer_features)[0][1]\n",
        "\n",
        "            # Segment assignment\n",
        "            segment = self.ml_models['segmentation'].predict(customer_scaled)[0]\n",
        "\n",
        "            # Update profile\n",
        "            profile['churn_probability'] = float(churn_prob)\n",
        "            profile['churn_risk'] = churn_risk\n",
        "            profile['segment'] = int(segment)\n",
        "            profile['propensity_scores'] = {\n",
        "                'upsell': float(base_propensity * 0.9),\n",
        "                'cross_sell': float(base_propensity * 0.8),\n",
        "                'premium_upgrade': float(base_propensity * 0.7),\n",
        "                'addon_services': float(base_propensity * 0.85)\n",
        "            }\n",
        "\n",
        "            # Calculate CLV (simplified)\n",
        "            monthly_charges = profile['features'].get('MonthlyCharges', 50)\n",
        "            tenure = profile['features'].get('tenure', 12)\n",
        "            profile['lifetime_value'] = float(monthly_charges * (tenure + 12 * (1 - churn_prob)))\n",
        "\n",
        "        print(f\"‚úì Enriched {len(self.customer_profiles)} customer profiles with predictions\")\n",
        "\n",
        "    def analyze_customer_with_ai(self, customer_id, profile):\n",
        "        \"\"\"Use AI agents to deeply analyze an individual customer\"\"\"\n",
        "\n",
        "        if not self.use_ai:\n",
        "            return self.generate_rule_based_strategy(profile)\n",
        "\n",
        "        # Create customer summary for AI analysis\n",
        "        customer_summary = f\"\"\"\n",
        "INDIVIDUAL CUSTOMER ANALYSIS REQUEST\n",
        "Customer ID: {customer_id}\n",
        "=====================================\n",
        "\n",
        "PROFILE DATA:\n",
        "- Churn Risk: {profile['churn_risk']} ({profile['churn_probability']:.1%} probability)\n",
        "- Customer Lifetime Value: ${profile['lifetime_value']:.2f}\n",
        "- Tenure: {profile['features'].get('tenure', 'N/A')} months\n",
        "- Monthly Charges: ${profile['features'].get('MonthlyCharges', 'N/A')}\n",
        "- Contract Type: {profile['features'].get('Contract', 'N/A')}\n",
        "- Internet Service: {profile['features'].get('InternetService', 'N/A')}\n",
        "- Segment: Micro-segment #{profile['segment']}\n",
        "\n",
        "PROPENSITY SCORES:\n",
        "- Upsell: {profile['propensity_scores']['upsell']:.1%}\n",
        "- Cross-sell: {profile['propensity_scores']['cross_sell']:.1%}\n",
        "- Premium Upgrade: {profile['propensity_scores']['premium_upgrade']:.1%}\n",
        "- Add-on Services: {profile['propensity_scores']['addon_services']:.1%}\n",
        "\n",
        "TASK:\n",
        "Analyze this SPECIFIC individual customer and provide:\n",
        "1. Predicted customer intent and next likely action\n",
        "2. Personalized retention/upsell strategy\n",
        "3. Specific product/service recommendations\n",
        "4. Optimal timing and channel for engagement\n",
        "5. Expected revenue impact\n",
        "\n",
        "Respond in JSON format with your analysis.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Sequential AI agent analysis\n",
        "            print(f\"      ‚Üí Intent Agent analyzing...\")\n",
        "            intent_response = self.intent_agent.analyze(customer_summary)\n",
        "\n",
        "            print(f\"      ‚Üí Propensity Agent analyzing...\")\n",
        "            propensity_response = self.propensity_agent.analyze(customer_summary)\n",
        "\n",
        "            print(f\"      ‚Üí Churn Agent analyzing...\")\n",
        "            churn_response = self.churn_agent.analyze(customer_summary)\n",
        "\n",
        "            # Synthesize insights with orchestrator\n",
        "            print(f\"      ‚Üí Orchestrator synthesizing...\")\n",
        "            synthesis_prompt = f\"\"\"\n",
        "Based on the following AI agent analyses for customer {customer_id}, create a unified personalization strategy:\n",
        "\n",
        "INTENT ANALYSIS:\n",
        "{intent_response}\n",
        "\n",
        "PROPENSITY ANALYSIS:\n",
        "{propensity_response}\n",
        "\n",
        "CHURN ANALYSIS:\n",
        "{churn_response}\n",
        "\n",
        "Synthesize these into a cohesive strategy with:\n",
        "1. Primary intent prediction\n",
        "2. Top 3 recommended actions\n",
        "3. Retention strategy (if needed)\n",
        "4. Upsell recommendations (if appropriate)\n",
        "5. Optimal engagement plan\n",
        "\n",
        "Return as JSON with keys: intent, next_actions, retention_strategy, upsell_recommendations, engagement_plan\n",
        "\"\"\"\n",
        "            orchestrator_response = self.orchestrator_agent.analyze(synthesis_prompt)\n",
        "\n",
        "            # Extract structured insights\n",
        "            ai_insights = self.parse_ai_response(orchestrator_response, profile)\n",
        "\n",
        "            # Reset chat histories for next customer\n",
        "            self.intent_agent.reset_chat()\n",
        "            self.propensity_agent.reset_chat()\n",
        "            self.churn_agent.reset_chat()\n",
        "            self.orchestrator_agent.reset_chat()\n",
        "\n",
        "            return ai_insights\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† AI analysis failed for {customer_id}: {e}\")\n",
        "            return self.generate_rule_based_strategy(profile)\n",
        "\n",
        "    def parse_ai_response(self, response_text: str, profile: dict) -> dict:\n",
        "        \"\"\"Parse AI response into structured format\"\"\"\n",
        "        try:\n",
        "            # Try to extract JSON from response\n",
        "            import re\n",
        "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                parsed = json.loads(json_match.group())\n",
        "                return {\n",
        "                    'intent': parsed.get('intent', 'Analyzed'),\n",
        "                    'next_actions': parsed.get('next_actions', [])[:3],\n",
        "                    'retention_strategy': parsed.get('retention_strategy', 'AI-generated'),\n",
        "                    'upsell_recommendations': parsed.get('upsell_recommendations', []),\n",
        "                    'engagement_plan': parsed.get('engagement_plan', {}),\n",
        "                    'ai_powered': True\n",
        "                }\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Fallback: extract key information from text\n",
        "        insights = {\n",
        "            'intent': 'Analyzed by AI',\n",
        "            'next_actions': [],\n",
        "            'retention_strategy': None,\n",
        "            'upsell_recommendations': [],\n",
        "            'engagement_plan': {},\n",
        "            'ai_powered': True\n",
        "        }\n",
        "\n",
        "        response_lower = response_text.lower()\n",
        "\n",
        "        # Extract intent\n",
        "        if 'churn' in response_lower or 'leave' in response_lower:\n",
        "            insights['intent'] = 'At Risk'\n",
        "        elif 'upgrade' in response_lower or 'upsell' in response_lower:\n",
        "            insights['intent'] = 'Growth Opportunity'\n",
        "        else:\n",
        "            insights['intent'] = 'Maintain'\n",
        "\n",
        "        # Extract actions based on risk\n",
        "        if profile['churn_risk'] == 'High':\n",
        "            insights['next_actions'] = [\n",
        "                'Immediate retention offer',\n",
        "                'Personal account manager outreach',\n",
        "                'Special loyalty program enrollment'\n",
        "            ]\n",
        "            insights['retention_strategy'] = 'AI-powered high-priority retention'\n",
        "        elif profile['churn_risk'] == 'Medium':\n",
        "            insights['next_actions'] = [\n",
        "                'Proactive satisfaction check',\n",
        "                'Service enhancement offer',\n",
        "                'Engagement campaign'\n",
        "            ]\n",
        "        else:\n",
        "            insights['next_actions'] = [\n",
        "                'Upsell premium features',\n",
        "                'Cross-sell complementary services',\n",
        "                'VIP program invitation'\n",
        "            ]\n",
        "            if max(profile['propensity_scores'].values()) > 0.6:\n",
        "                insights['upsell_recommendations'] = [\n",
        "                    k for k, v in profile['propensity_scores'].items() if v > 0.6\n",
        "                ]\n",
        "\n",
        "        return insights\n",
        "\n",
        "    def generate_rule_based_strategy(self, profile):\n",
        "        \"\"\"Fallback: Generate personalized strategy using rules\"\"\"\n",
        "        strategy = {\n",
        "            'intent': 'Stay' if profile['churn_probability'] < 0.3 else 'At Risk',\n",
        "            'next_actions': [],\n",
        "            'retention_strategy': None,\n",
        "            'upsell_recommendations': [],\n",
        "            'engagement_plan': {},\n",
        "            'ai_powered': False\n",
        "        }\n",
        "\n",
        "        # Determine actions based on profile\n",
        "        if profile['churn_risk'] == 'High':\n",
        "            strategy['next_actions'] = [\n",
        "                'Immediate retention offer',\n",
        "                'Personal outreach from account manager',\n",
        "                'Special loyalty discount'\n",
        "            ]\n",
        "            strategy['retention_strategy'] = f\"High-priority retention: Offer ${profile['features'].get('MonthlyCharges', 50) * 0.2:.2f} discount\"\n",
        "        elif profile['churn_risk'] == 'Medium':\n",
        "            strategy['next_actions'] = [\n",
        "                'Send satisfaction survey',\n",
        "                'Offer service upgrade trial',\n",
        "                'Check for service issues'\n",
        "            ]\n",
        "        else:\n",
        "            # Low churn risk - focus on growth\n",
        "            if max(profile['propensity_scores'].values()) > 0.6:\n",
        "                strategy['next_actions'] = [\n",
        "                    'Upsell premium services',\n",
        "                    'Cross-sell complementary products'\n",
        "                ]\n",
        "                strategy['upsell_recommendations'] = [\n",
        "                    k for k, v in profile['propensity_scores'].items() if v > 0.6\n",
        "                ]\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def run_hyper_personalization(self, num_customers=10):\n",
        "        \"\"\"\n",
        "        Run AI-powered hyper-personalization for individual customers\n",
        "\n",
        "        This demonstrates the AI-first approach: each customer gets individual\n",
        "        analysis and personalized strategies, not generic persona-based treatment\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"ü§ñ\" * 40)\n",
        "        print(\"AI-POWERED HYPER-PERSONALIZATION ENGINE\")\n",
        "        print(\"Individual-Centric Intelligence (Not Persona-Based)\")\n",
        "        print(\"ü§ñ\" * 40)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Analyze a sample of customers individually\n",
        "        customer_sample = list(self.customer_profiles.items())[:num_customers]\n",
        "\n",
        "        print(f\"\\nüîç Analyzing {len(customer_sample)} individual customers with AI agents...\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for idx, (customer_id, profile) in enumerate(customer_sample, 1):\n",
        "            print(f\"\\n[{idx}/{len(customer_sample)}] Analyzing Customer: {customer_id}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            # Display customer snapshot\n",
        "            print(f\"  Churn Risk: {profile['churn_risk']} ({profile['churn_probability']:.1%})\")\n",
        "            print(f\"  CLV: ${profile['lifetime_value']:.2f}\")\n",
        "            print(f\"  Segment: #{profile['segment']}\")\n",
        "\n",
        "            # AI-powered individual analysis\n",
        "            if self.use_ai and idx <= 3:  # Analyze first 3 with AI (to save API calls)\n",
        "                print(f\"  ü§ñ Running AI agent analysis...\")\n",
        "                ai_strategy = self.analyze_customer_with_ai(customer_id, profile)\n",
        "            else:\n",
        "                print(f\"  üìä Generating rule-based strategy...\")\n",
        "                ai_strategy = self.generate_rule_based_strategy(profile)\n",
        "\n",
        "            # Update profile with personalized strategy\n",
        "            profile['personalized_strategy'] = ai_strategy\n",
        "            profile['next_best_actions'] = ai_strategy.get('next_actions', [])\n",
        "\n",
        "            # Display strategy\n",
        "            print(f\"  ‚úì Strategy Generated:\")\n",
        "            print(f\"    Intent: {ai_strategy.get('intent', 'N/A')}\")\n",
        "            actions = ai_strategy.get('next_actions', ['None'])\n",
        "            print(f\"    Actions: {', '.join(actions[:2]) if actions else 'None'}\")\n",
        "\n",
        "            results.append({\n",
        "                'customer_id': customer_id,\n",
        "                'profile': profile,\n",
        "                'strategy': ai_strategy\n",
        "            })\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"‚úÖ COMPLETED: {len(results)} customers analyzed individually\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_business_impact_report(self, results):\n",
        "        \"\"\"Generate business impact analysis\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"BUSINESS IMPACT ANALYSIS\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        total_customers = len(results)\n",
        "        high_risk = sum(1 for r in results if r['profile']['churn_risk'] == 'High')\n",
        "        medium_risk = sum(1 for r in results if r['profile']['churn_risk'] == 'Medium')\n",
        "        total_clv_at_risk = sum(r['profile']['lifetime_value']\n",
        "                               for r in results\n",
        "                               if r['profile']['churn_risk'] in ['High', 'Medium'])\n",
        "\n",
        "        avg_churn_prob = np.mean([r['profile']['churn_probability'] for r in results])\n",
        "\n",
        "        print(f\"\\nüìä CUSTOMER RISK DISTRIBUTION:\")\n",
        "        print(f\"   High Risk: {high_risk} customers ({high_risk/total_customers*100:.1f}%)\")\n",
        "        print(f\"   Medium Risk: {medium_risk} customers ({medium_risk/total_customers*100:.1f}%)\")\n",
        "        print(f\"   Low Risk: {total_customers - high_risk - medium_risk} customers\")\n",
        "\n",
        "        print(f\"\\nüí∞ FINANCIAL IMPACT:\")\n",
        "        print(f\"   Total CLV at Risk: ${total_clv_at_risk:,.2f}\")\n",
        "        print(f\"   Average Churn Probability: {avg_churn_prob:.1%}\")\n",
        "        print(f\"   Potential Saved Revenue (50% retention): ${total_clv_at_risk * 0.5:,.2f}\")\n",
        "\n",
        "        print(f\"\\nüéØ PERSONALIZATION INSIGHTS:\")\n",
        "        print(f\"   Individual Profiles Created: {len(self.customer_profiles)}\")\n",
        "        ai_powered = sum(1 for r in results if r['strategy'].get('ai_powered', False))\n",
        "        print(f\"   AI-Powered Strategies: {ai_powered}\")\n",
        "        print(f\"   Micro-Segments Identified: 20 (vs typical 5-10 personas)\")\n",
        "\n",
        "        return {\n",
        "            'total_customers': total_customers,\n",
        "            'high_risk': high_risk,\n",
        "            'clv_at_risk': total_clv_at_risk,\n",
        "            'potential_savings': total_clv_at_risk * 0.5\n",
        "        }\n",
        "\n",
        "    def run_full_pipeline(self, analyze_customers=10):\n",
        "        \"\"\"Run the complete hyper-personalization pipeline\"\"\"\n",
        "        print(\"\\n\" + \"üöÄ\" * 40)\n",
        "        print(\"AI-DRIVEN HYPER-PERSONALIZATION & CHURN INTELLIGENCE PLATFORM\")\n",
        "        print(\"üöÄ\" * 40)\n",
        "\n",
        "        # 1. Load data and create individual profiles\n",
        "        self.load_and_prepare_data()\n",
        "\n",
        "        # 2. Build ML foundation\n",
        "        self.build_ml_foundation()\n",
        "\n",
        "        # 3. Enrich profiles with predictions\n",
        "        self.enrich_profiles_with_predictions()\n",
        "\n",
        "        # 4. Run AI-powered hyper-personalization\n",
        "        results = self.run_hyper_personalization(num_customers=analyze_customers)\n",
        "\n",
        "        # 5. Generate business impact report\n",
        "        impact = self.generate_business_impact_report(results)\n",
        "\n",
        "        print(\"\\n\" + \"‚úÖ\" * 40)\n",
        "        print(\"PIPELINE COMPLETED!\")\n",
        "        print(\"‚úÖ\" * 40)\n",
        "\n",
        "        print(\"\\nüí° KEY DIFFERENTIATORS FROM TRADITIONAL APPROACHES:\")\n",
        "        print(\"   ‚úì Individual customer profiles (not generic personas)\")\n",
        "        print(\"   ‚úì AI agents analyze each customer separately\")\n",
        "        print(\"   ‚úì Real-time personalized strategies\")\n",
        "        print(\"   ‚úì Intent prediction at individual level\")\n",
        "        print(\"   ‚úì Dynamic propensity scoring\")\n",
        "        print(\"   ‚úì Proactive churn prevention with personalized offers\")\n",
        "\n",
        "        return {\n",
        "            'results': results,\n",
        "            'impact': impact,\n",
        "            'total_profiles': len(self.customer_profiles)\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"AI-DRIVEN HYPER-PERSONALIZATION & CHURN INTELLIGENCE PLATFORM\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nSolving: Individual-level behavior prediction vs persona-based segmentation\")\n",
        "    print(\"Approach: AI-first, adaptive, real-time personalization at scale\")\n",
        "    print(\"Powered by: OpenRouter (Free Models) with API key rotation\")\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "    # OPTION 1: Use environment variables (recommended)\n",
        "    # Set these in your .env file or environment:\n",
        "    # OPENROUTER_API_KEY_1=sk-or-v1-...\n",
        "    # OPENROUTER_API_KEY_2=sk-or-v1-...\n",
        "    # OPENROUTER_API_KEY_3=sk-or-v1-...\n",
        "\n",
        "    engine = HyperPersonalizationEngine(\n",
        "        data_path='WA_Fn-UseC_-Telco-Customer-Churn.csv',\n",
        "        use_ai_agents=True,  # Set to False for faster testing without AI\n",
        "        api_keys=[\n",
        "              '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',\n",
        "              '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',\n",
        "              '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'\n",
        "         ]  # Will use environment variables\n",
        "    )\n",
        "\n",
        "    # OPTION 2: Pass API keys directly (less secure, not recommended for production)\n",
        "    # engine = HyperPersonalizationEngine(\n",
        "    #     data_path='WA_Fn-UseC_-Telco-Customer-Churn.csv',\n",
        "    #     use_ai_agents=True,\n",
        "    #     api_keys=[\n",
        "    #         'sk-or-v1-your-key-1-here',\n",
        "    #         'sk-or-v1-your-key-2-here',\n",
        "    #         'sk-or-v1-your-key-3-here'\n",
        "    #     ]\n",
        "    # )\n",
        "\n",
        "    # Run the full pipeline\n",
        "    # analyze_customers: number of customers to deeply analyze with AI (set lower for faster demo)\n",
        "    results = engine.run_full_pipeline(analyze_customers=5)\n",
        "\n",
        "    print(\"\\nüìã USAGE NOTES:\")\n",
        "    print(\"   ‚Ä¢ To analyze more customers with AI, increase 'analyze_customers' parameter\")\n",
        "    print(\"   ‚Ä¢ To export results: results['results'] contains individual strategies\")\n",
        "    print(\"\\nüîë API KEY SETUP:\")\n",
        "    print(\"   ‚Ä¢ Get free API keys from: https://openrouter.ai/keys\")\n",
        "    print(\"   ‚Ä¢ Set environment variables: OPENROUTER_API_KEY_1, OPENROUTER_API_KEY_2, OPENROUTER_API_KEY_3\")\n",
        "    print(\"   ‚Ä¢ Or pass keys directly: api_keys=['key1', 'key2', 'key3']\")\n",
        "    print(\"\\nü§ñ FREE MODELS USED (with automatic fallback):\")\n",
        "    print(\"   1. meta-llama/llama-3.2-3b-instruct:free\")\n",
        "    print(\"   2. google/gemini-flash-1.5:free\")\n",
        "    print(\"   3. nousresearch/hermes-3-llama-3.1-405b:free\")\n",
        "    print(\"\\nüí° BENEFITS OF API KEY & MODEL ROTATION:\")\n",
        "    print(\"   ‚Ä¢ Automatic failover on rate limits or model unavailability\")\n",
        "    print(\"   ‚Ä¢ Higher throughput with multiple keys\")\n",
        "    print(\"   ‚Ä¢ Resilience against temporary API issues\")\n",
        "    print(\"   ‚Ä¢ No privacy policy configuration needed!\")\n",
        "    print(\"\\n‚ö†Ô∏è  TROUBLESHOOTING:\")\n",
        "    print(\"   ‚Ä¢ If you see 404 errors about privacy policy:\")\n",
        "    print(\"     Visit https://openrouter.ai/settings/privacy and allow free models\")\n",
        "    print(\"   ‚Ä¢ Or the system will automatically try alternative free models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIKhDFKEkq8x",
        "outputId": "caecdbcc-8231-4bf9-9084-300ee1d8acbf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing churn_pred.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Import the hyper-personalization engine from curn_pred.py\n",
        "try:\n",
        "    from churn_pred import HyperPersonalizationEngine, OpenRouterConfig, AIAgent\n",
        "    ENGINE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    ENGINE_AVAILABLE = False\n",
        "    st.error(\"‚ö†Ô∏è Could not import HyperPersonalizationEngine. Make sure curn_pred.py is in the same directory.\")\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Hyper-Personalization Platform\",\n",
        "    page_icon=\"ü§ñ\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: bold;\n",
        "        color: #1f77b4;\n",
        "        text-align: center;\n",
        "        padding: 1rem 0;\n",
        "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        color: white;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .customer-card {\n",
        "        background: white;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 10px;\n",
        "        border-left: 4px solid #667eea;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .risk-high {\n",
        "        color: #dc3545;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .risk-medium {\n",
        "        color: #ffc107;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .risk-low {\n",
        "        color: #28a745;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .stButton>button {\n",
        "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        padding: 0.5rem 2rem;\n",
        "        border-radius: 5px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state\n",
        "if 'engine' not in st.session_state:\n",
        "    st.session_state.engine = None\n",
        "if 'analysis_complete' not in st.session_state:\n",
        "    st.session_state.analysis_complete = False\n",
        "if 'results' not in st.session_state:\n",
        "    st.session_state.results = None\n",
        "if 'ai_strategies' not in st.session_state:\n",
        "    st.session_state.ai_strategies = {}\n",
        "if 'api_key_1' not in st.session_state:\n",
        "    st.session_state.api_key_1 = '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'\n",
        "if 'api_key_2' not in st.session_state:\n",
        "    st.session_state.api_key_2 = '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'\n",
        "if 'api_key_3' not in st.session_state:\n",
        "    st.session_state.api_key_3 = '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'\n",
        "\n",
        "# Sidebar\n",
        "st.sidebar.markdown(\"# ü§ñ AI Platform\")\n",
        "st.sidebar.markdown(\"---\")\n",
        "\n",
        "# Navigation\n",
        "page = st.sidebar.radio(\n",
        "    \"Navigation\",\n",
        "    [\"üè† Dashboard\", \"üë• Customer Intelligence\", \"üìä Analytics\", \"üéØ Personalization\", \"‚öôÔ∏è Settings\"]\n",
        ")\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.markdown(\"### System Status\")\n",
        "if st.session_state.engine:\n",
        "    st.sidebar.success(\"‚úÖ Engine Running\")\n",
        "    st.sidebar.info(f\"üìä {len(st.session_state.engine.customer_profiles)} Profiles\")\n",
        "else:\n",
        "    st.sidebar.warning(\"‚ö†Ô∏è Engine Not Initialized\")\n",
        "\n",
        "# Main header\n",
        "st.markdown('<h1 class=\"main-header\">ü§ñ AI-Driven Hyper-Personalization & Churn Intelligence Platform</h1>', unsafe_allow_html=True)\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# HELPER FUNCTION: Generate AI Strategy with Retry Logic\n",
        "# ==============================================================================\n",
        "\n",
        "def generate_ai_strategy_with_retry(engine, customer_id, profile, max_retries=3):\n",
        "    \"\"\"\n",
        "    Generate AI strategy for a specific customer with retry logic\n",
        "    Similar to the retry logic in curn_pred.py\n",
        "    \"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            with st.spinner(f\"ü§ñ Attempt {attempt + 1}/{max_retries}: Generating AI strategy...\"):\n",
        "                # Use the engine's AI method\n",
        "                strategy = engine.analyze_customer_with_ai(customer_id, profile)\n",
        "\n",
        "                if strategy and 'intent' in strategy:\n",
        "                    st.success(f\"‚úÖ AI strategy generated successfully on attempt {attempt + 1}!\")\n",
        "                    return strategy\n",
        "                else:\n",
        "                    st.warning(f\"‚ö†Ô∏è Attempt {attempt + 1} returned incomplete data\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.warning(f\"‚ö†Ô∏è Attempt {attempt + 1} failed: {str(e)}\")\n",
        "\n",
        "        if attempt < max_retries - 1:\n",
        "            time.sleep(1)  # Wait before retry\n",
        "\n",
        "    # If all retries fail, generate rule-based strategy\n",
        "    st.info(\"üìä All AI attempts failed. Generating rule-based strategy as fallback...\")\n",
        "    return engine.generate_rule_based_strategy(profile)\n",
        "\n",
        "# ==============================================================================\n",
        "# PAGE 1: DASHBOARD\n",
        "# ==============================================================================\n",
        "\n",
        "if page == \"üè† Dashboard\":\n",
        "    st.markdown(\"## üìä Executive Dashboard\")\n",
        "    st.markdown(\"Real-time individual-centric customer intelligence\")\n",
        "\n",
        "    # File upload and initialization\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        uploaded_file = st.file_uploader(\"Upload Customer Data (CSV)\", type=['csv'])\n",
        "\n",
        "    with col2:\n",
        "        use_ai = st.checkbox(\"Enable AI Agents\", value=True, help=\"Enable AI-powered analysis (requires API key)\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        if st.button(\"üöÄ Run Analysis\", key=\"run_analysis\"):\n",
        "            with st.spinner(\"Initializing AI Hyper-Personalization Engine...\"):\n",
        "                # Save uploaded file temporarily\n",
        "                import tempfile\n",
        "                import os\n",
        "\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:\n",
        "                    tmp_file.write(uploaded_file.getvalue())\n",
        "                    tmp_path = tmp_file.name\n",
        "\n",
        "                try:\n",
        "                    # Collect API keys from session state\n",
        "                    api_keys = [k for k in [st.session_state.api_key_1, st.session_state.api_key_2, st.session_state.api_key_3] if k]\n",
        "\n",
        "                    # Initialize engine\n",
        "                    st.session_state.engine = HyperPersonalizationEngine(\n",
        "                        data_path=tmp_path,\n",
        "                        use_ai_agents=use_ai,\n",
        "                        api_keys=api_keys if api_keys else None\n",
        "                    )\n",
        "\n",
        "                    # Run pipeline (load data and build profiles)\n",
        "                    with st.spinner(\"Building customer profiles and predictions...\"):\n",
        "                        st.session_state.engine.load_and_prepare_data()\n",
        "                        st.session_state.engine.build_ml_foundation()\n",
        "                        st.session_state.engine.enrich_profiles_with_predictions()\n",
        "\n",
        "                        # Create results structure\n",
        "                        results = {\n",
        "                            'total_profiles': len(st.session_state.engine.customer_profiles),\n",
        "                            'impact': {\n",
        "                                'total_customers': len(st.session_state.engine.customer_profiles),\n",
        "                                'high_risk': sum(1 for p in st.session_state.engine.customer_profiles.values() if p['churn_risk'] == 'High'),\n",
        "                                'clv_at_risk': sum(p['lifetime_value'] for p in st.session_state.engine.customer_profiles.values() if p['churn_risk'] in ['High', 'Medium']),\n",
        "                                'potential_savings': sum(p['lifetime_value'] for p in st.session_state.engine.customer_profiles.values() if p['churn_risk'] in ['High', 'Medium']) * 0.5\n",
        "                            }\n",
        "                        }\n",
        "\n",
        "                        st.session_state.results = results\n",
        "                        st.session_state.analysis_complete = True\n",
        "\n",
        "                    st.success(\"‚úÖ Analysis Complete!\")\n",
        "                    st.rerun()\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"‚ùå Error: {str(e)}\")\n",
        "                    import traceback\n",
        "                    st.error(traceback.format_exc())\n",
        "                finally:\n",
        "                    # Clean up temp file\n",
        "                    if os.path.exists(tmp_path):\n",
        "                        os.unlink(tmp_path)\n",
        "\n",
        "    # Display results if analysis is complete\n",
        "    if st.session_state.analysis_complete and st.session_state.results:\n",
        "        results = st.session_state.results\n",
        "        impact = results['impact']\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### üìà Key Metrics\")\n",
        "\n",
        "        # Metrics row\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <h3>üë• Total Customers</h3>\n",
        "                <h2>{results['total_profiles']:,}</h2>\n",
        "                <p>Individual Profiles</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <h3>‚ö†Ô∏è High Risk</h3>\n",
        "                <h2>{impact['high_risk']}</h2>\n",
        "                <p>Immediate Action Needed</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col3:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <h3>üí∞ CLV at Risk</h3>\n",
        "                <h2>${impact['clv_at_risk']:,.0f}</h2>\n",
        "                <p>Potential Revenue Loss</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        with col4:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"metric-card\">\n",
        "                <h3>üíµ Potential Savings</h3>\n",
        "                <h2>${impact['potential_savings']:,.0f}</h2>\n",
        "                <p>With AI Intervention</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Charts\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(\"### üéØ Risk Distribution\")\n",
        "\n",
        "            # Count risk levels\n",
        "            risk_counts = {'High': 0, 'Medium': 0, 'Low': 0}\n",
        "            for profile in st.session_state.engine.customer_profiles.values():\n",
        "                risk_counts[profile['churn_risk']] += 1\n",
        "\n",
        "            fig = go.Figure(data=[go.Pie(\n",
        "                labels=list(risk_counts.keys()),\n",
        "                values=list(risk_counts.values()),\n",
        "                marker_colors=['#dc3545', '#ffc107', '#28a745']\n",
        "            )])\n",
        "            fig.update_layout(showlegend=True)\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(\"### üí∞ Top 10 Micro-Segments\")\n",
        "\n",
        "            # Count segments\n",
        "            segment_counts = {}\n",
        "            for profile in st.session_state.engine.customer_profiles.values():\n",
        "                seg = profile['segment']\n",
        "                segment_counts[seg] = segment_counts.get(seg, 0) + 1\n",
        "\n",
        "            # Top 10 segments\n",
        "            top_segments = sorted(segment_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "            fig = go.Figure(data=[go.Bar(\n",
        "                x=[f\"Seg {s[0]}\" for s in top_segments],\n",
        "                y=[s[1] for s in top_segments],\n",
        "                marker_color='#667eea'\n",
        "            )])\n",
        "            fig.update_layout(height=350, xaxis_title=\"Segment\", yaxis_title=\"Customers\")\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Top insights\n",
        "        st.markdown(\"### üí° AI-Generated Insights\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        with col1:\n",
        "            st.info(\"üéØ **Intent Prediction**\\nAI can analyze individual customer intents on-demand for personalized strategies\")\n",
        "\n",
        "        with col2:\n",
        "            st.success(\"üìà **Propensity Scores**\\nPersonalized upsell opportunities identified for each customer\")\n",
        "\n",
        "        with col3:\n",
        "            st.warning(\"üõ°Ô∏è **Churn Prevention**\\nProactive retention strategies can be generated per individual with AI\")\n",
        "\n",
        "# ==============================================================================\n",
        "# PAGE 2: CUSTOMER INTELLIGENCE (MODIFIED WITH AI BUTTON)\n",
        "# ==============================================================================\n",
        "\n",
        "elif page == \"üë• Customer Intelligence\":\n",
        "    st.markdown(\"## üë• Individual Customer Intelligence\")\n",
        "\n",
        "    if not st.session_state.engine:\n",
        "        st.warning(\"‚ö†Ô∏è Please run analysis from Dashboard first\")\n",
        "    else:\n",
        "        engine = st.session_state.engine\n",
        "\n",
        "        # Search/filter\n",
        "        col1, col2, col3 = st.columns([2, 1, 1])\n",
        "\n",
        "        with col1:\n",
        "            search_id = st.text_input(\"üîç Search Customer ID\", placeholder=\"Enter customer ID...\")\n",
        "\n",
        "        with col2:\n",
        "            risk_filter = st.selectbox(\"Filter by Risk\", [\"All\", \"High\", \"Medium\", \"Low\"])\n",
        "\n",
        "        with col3:\n",
        "            sort_by = st.selectbox(\"Sort by\", [\"Churn Risk\", \"CLV\", \"Tenure\"])\n",
        "\n",
        "        # Get filtered customers\n",
        "        customers = list(engine.customer_profiles.items())\n",
        "\n",
        "        if risk_filter != \"All\":\n",
        "            customers = [(cid, p) for cid, p in customers if p['churn_risk'] == risk_filter]\n",
        "\n",
        "        if search_id:\n",
        "            customers = [(cid, p) for cid, p in customers if search_id.lower() in str(cid).lower()]\n",
        "\n",
        "        # Sort\n",
        "        if sort_by == \"Churn Risk\":\n",
        "            customers = sorted(customers, key=lambda x: x[1]['churn_probability'], reverse=True)\n",
        "        elif sort_by == \"CLV\":\n",
        "            customers = sorted(customers, key=lambda x: x[1]['lifetime_value'], reverse=True)\n",
        "\n",
        "        st.markdown(f\"### Showing {len(customers)} customers\")\n",
        "\n",
        "        # Pagination\n",
        "        items_per_page = 10\n",
        "        total_pages = (len(customers) - 1) // items_per_page + 1 if len(customers) > 0 else 1\n",
        "        page_num = st.number_input(\"Page\", min_value=1, max_value=total_pages, value=1)\n",
        "\n",
        "        start_idx = (page_num - 1) * items_per_page\n",
        "        end_idx = start_idx + items_per_page\n",
        "\n",
        "        # Display customers\n",
        "        for customer_id, profile in customers[start_idx:end_idx]:\n",
        "            risk_class = f\"risk-{profile['churn_risk'].lower()}\"\n",
        "\n",
        "            with st.expander(f\"**{customer_id}** - {profile['churn_risk']} Risk ({profile['churn_probability']:.1%})\"):\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                with col1:\n",
        "                    st.markdown(\"#### üìä Profile\")\n",
        "                    st.write(f\"**CLV:** ${profile['lifetime_value']:,.2f}\")\n",
        "                    st.write(f\"**Tenure:** {profile['features'].get('tenure', 'N/A')} months\")\n",
        "                    st.write(f\"**Monthly:** ${profile['features'].get('MonthlyCharges', 'N/A')}\")\n",
        "                    st.write(f\"**Segment:** #{profile['segment']}\")\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(\"#### üéØ Propensity Scores\")\n",
        "                    for key, score in profile['propensity_scores'].items():\n",
        "                        st.progress(score, text=f\"{key}: {score:.1%}\")\n",
        "\n",
        "                with col3:\n",
        "                    st.markdown(\"#### üí° Next Best Actions\")\n",
        "\n",
        "                    # Check if AI strategy exists\n",
        "                    if customer_id in st.session_state.ai_strategies:\n",
        "                        actions = st.session_state.ai_strategies[customer_id].get('next_actions', ['No actions available'])\n",
        "                        for action in actions[:3]:\n",
        "                            st.write(f\"‚Ä¢ {action}\")\n",
        "                    else:\n",
        "                        st.info(\"Click button below to generate AI-powered action plan\")\n",
        "\n",
        "                # AI Strategy Generation Button\n",
        "                st.markdown(\"---\")\n",
        "                col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])\n",
        "\n",
        "                with col_btn1:\n",
        "                    if st.button(f\"ü§ñ Generate AI Actions\", key=f\"ai_btn_{customer_id}\"):\n",
        "                        # Generate strategy with retry logic\n",
        "                        strategy = generate_ai_strategy_with_retry(engine, customer_id, profile)\n",
        "\n",
        "                        # Store in session state\n",
        "                        st.session_state.ai_strategies[customer_id] = strategy\n",
        "                        st.rerun()\n",
        "\n",
        "                # Display AI strategy if generated\n",
        "                if customer_id in st.session_state.ai_strategies:\n",
        "                    with col_btn2:\n",
        "                        if st.button(f\"üóëÔ∏è Clear AI Data\", key=f\"clear_{customer_id}\"):\n",
        "                            del st.session_state.ai_strategies[customer_id]\n",
        "                            st.rerun()\n",
        "\n",
        "                    st.markdown(\"---\")\n",
        "                    st.markdown(\"#### ü§ñ AI-Generated Strategy\")\n",
        "\n",
        "                    strategy = st.session_state.ai_strategies[customer_id]\n",
        "\n",
        "                    col_a, col_b = st.columns(2)\n",
        "\n",
        "                    with col_a:\n",
        "                        st.markdown(\"**üéØ Customer Intent**\")\n",
        "                        st.info(strategy.get('intent', 'Unknown'))\n",
        "\n",
        "                        st.markdown(\"**üìä Key Insights**\")\n",
        "                        insights = strategy.get('insights', ['No insights available'])\n",
        "                        for insight in insights[:3]:\n",
        "                            st.write(f\"‚Ä¢ {insight}\")\n",
        "\n",
        "                    with col_b:\n",
        "                        st.markdown(\"**‚úÖ Recommended Actions**\")\n",
        "                        actions = strategy.get('next_actions', ['No actions available'])\n",
        "                        for idx, action in enumerate(actions[:5], 1):\n",
        "                            st.write(f\"{idx}. {action}\")\n",
        "\n",
        "                    # Show if AI-powered or rule-based\n",
        "                    if strategy.get('ai_powered', False):\n",
        "                        st.success(\"ü§ñ Generated with AI\")\n",
        "                    else:\n",
        "                        st.warning(\"üìä Rule-based strategy (AI unavailable)\")\n",
        "\n",
        "                    # Show full strategy as JSON\n",
        "                    with st.expander(\"üìã View Full Strategy (JSON)\"):\n",
        "                        st.json(strategy)\n",
        "\n",
        "# ==============================================================================\n",
        "# PAGE 3: ANALYTICS\n",
        "# ==============================================================================\n",
        "\n",
        "elif page == \"üìä Analytics\":\n",
        "    st.markdown(\"## üìä Advanced Analytics\")\n",
        "\n",
        "    if not st.session_state.engine:\n",
        "        st.warning(\"‚ö†Ô∏è Please run analysis from Dashboard first\")\n",
        "    else:\n",
        "        engine = st.session_state.engine\n",
        "\n",
        "        tab1, tab2, tab3 = st.tabs([\"üìà Churn Analysis\", \"üí∞ Revenue Impact\", \"üéØ Propensity Analysis\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.markdown(\"### Churn Risk Analysis\")\n",
        "\n",
        "            # Create dataframe\n",
        "            data = []\n",
        "            for cid, profile in engine.customer_profiles.items():\n",
        "                data.append({\n",
        "                    'customer_id': cid,\n",
        "                    'churn_prob': profile['churn_probability'],\n",
        "                    'churn_risk': profile['churn_risk'],\n",
        "                    'clv': profile['lifetime_value'],\n",
        "                    'tenure': profile['features'].get('tenure', 0),\n",
        "                    'monthly': profile['features'].get('MonthlyCharges', 0),\n",
        "                    'segment': profile['segment']\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(data)\n",
        "\n",
        "            # Scatter plot\n",
        "            fig = px.scatter(\n",
        "                df,\n",
        "                x='tenure',\n",
        "                y='churn_prob',\n",
        "                size='clv',\n",
        "                color='churn_risk',\n",
        "                hover_data=['customer_id', 'monthly'],\n",
        "                title=\"Churn Probability vs Tenure (bubble size = CLV)\",\n",
        "                color_discrete_map={'High': '#dc3545', 'Medium': '#ffc107', 'Low': '#28a745'}\n",
        "            )\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Distribution\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                fig = px.histogram(df, x='churn_prob', nbins=50, title=\"Churn Probability Distribution\")\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            with col2:\n",
        "                fig = px.box(df, x='churn_risk', y='clv', title=\"CLV by Risk Level\")\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        with tab2:\n",
        "            st.markdown(\"### Revenue Impact Analysis\")\n",
        "\n",
        "            # Revenue at risk by segment\n",
        "            segment_risk = df.groupby('segment').agg({\n",
        "                'clv': 'sum',\n",
        "                'churn_prob': 'mean'\n",
        "            }).reset_index()\n",
        "            segment_risk['revenue_at_risk'] = segment_risk['clv'] * segment_risk['churn_prob']\n",
        "            segment_risk = segment_risk.sort_values('revenue_at_risk', ascending=False).head(10)\n",
        "\n",
        "            fig = go.Figure(data=[\n",
        "                go.Bar(name='Total CLV', x=segment_risk['segment'], y=segment_risk['clv']),\n",
        "                go.Bar(name='Revenue at Risk', x=segment_risk['segment'], y=segment_risk['revenue_at_risk'])\n",
        "            ])\n",
        "            fig.update_layout(barmode='group', title='Top 10 Segments by Revenue at Risk')\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Summary stats\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "\n",
        "            with col1:\n",
        "                total_clv = df['clv'].sum()\n",
        "                st.metric(\"Total Customer Value\", f\"${total_clv:,.0f}\")\n",
        "\n",
        "            with col2:\n",
        "                high_risk_clv = df[df['churn_risk'] == 'High']['clv'].sum()\n",
        "                st.metric(\"High Risk CLV\", f\"${high_risk_clv:,.0f}\", delta=f\"-{high_risk_clv/total_clv*100:.1f}%\")\n",
        "\n",
        "            with col3:\n",
        "                avg_clv = df['clv'].mean()\n",
        "                st.metric(\"Average CLV\", f\"${avg_clv:,.0f}\")\n",
        "\n",
        "        with tab3:\n",
        "            st.markdown(\"### Propensity Analysis\")\n",
        "\n",
        "            # Aggregate propensity scores\n",
        "            propensity_data = []\n",
        "            for profile in engine.customer_profiles.values():\n",
        "                for key, score in profile['propensity_scores'].items():\n",
        "                    propensity_data.append({\n",
        "                        'product': key,\n",
        "                        'score': score,\n",
        "                        'risk': profile['churn_risk']\n",
        "                    })\n",
        "\n",
        "            prop_df = pd.DataFrame(propensity_data)\n",
        "\n",
        "            # Average propensity by product\n",
        "            fig = px.box(prop_df, x='product', y='score', color='risk',\n",
        "                        title='Propensity Scores by Product and Risk Level')\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            # Opportunity matrix\n",
        "            st.markdown(\"### üéØ Opportunity Matrix\")\n",
        "\n",
        "            high_prop = prop_df[prop_df['score'] > 0.7].groupby(['product', 'risk']).size().reset_index(name='count')\n",
        "\n",
        "            fig = px.bar(high_prop, x='product', y='count', color='risk',\n",
        "                        title='High Propensity Customers (>70%) by Product',\n",
        "                        color_discrete_map={'High': '#dc3545', 'Medium': '#ffc107', 'Low': '#28a745'})\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# PAGE 4: PERSONALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "elif page == \"üéØ Personalization\":\n",
        "    st.markdown(\"## üéØ Personalization Campaigns\")\n",
        "\n",
        "    if not st.session_state.engine:\n",
        "        st.warning(\"‚ö†Ô∏è Please run analysis from Dashboard first\")\n",
        "    else:\n",
        "        engine = st.session_state.engine\n",
        "\n",
        "        st.markdown(\"### Create Targeted Campaign\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            campaign_type = st.selectbox(\n",
        "                \"Campaign Type\",\n",
        "                [\"Retention (High Risk)\", \"Upsell (Low Risk)\", \"Cross-sell\", \"Win-back\"]\n",
        "            )\n",
        "\n",
        "            target_segment = st.multiselect(\n",
        "                \"Target Segments\",\n",
        "                options=list(range(20)),\n",
        "                default=[0, 1, 2]\n",
        "            )\n",
        "\n",
        "        with col2:\n",
        "            risk_target = st.multiselect(\n",
        "                \"Risk Levels\",\n",
        "                [\"High\", \"Medium\", \"Low\"],\n",
        "                default=[\"High\"]\n",
        "            )\n",
        "\n",
        "            min_clv = st.number_input(\"Minimum CLV\", value=500.0)\n",
        "\n",
        "        if st.button(\"üéØ Generate Campaign\"):\n",
        "            # Filter customers\n",
        "            target_customers = []\n",
        "            for cid, profile in engine.customer_profiles.items():\n",
        "                if (profile['churn_risk'] in risk_target and\n",
        "                    profile['segment'] in target_segment and\n",
        "                    profile['lifetime_value'] >= min_clv):\n",
        "                    target_customers.append((cid, profile))\n",
        "\n",
        "            st.success(f\"‚úÖ Found {len(target_customers)} target customers\")\n",
        "\n",
        "            # Display sample\n",
        "            st.markdown(\"### üìã Sample Campaign Recipients\")\n",
        "\n",
        "            for cid, profile in target_customers[:5]:\n",
        "                # Get next action\n",
        "                if cid in st.session_state.ai_strategies:\n",
        "                    actions = st.session_state.ai_strategies[cid].get('next_actions', [])\n",
        "                    next_action = actions[0] if actions else \"No action available\"\n",
        "                else:\n",
        "                    next_action = \"Generate AI action plan in Customer Intelligence\"\n",
        "\n",
        "                st.markdown(f\"\"\"\n",
        "                <div class=\"customer-card\">\n",
        "                    <h4>{cid}</h4>\n",
        "                    <p><strong>Risk:</strong> <span class=\"risk-{profile['churn_risk'].lower()}\">{profile['churn_risk']}</span> |\n",
        "                    <strong>CLV:</strong> ${profile['lifetime_value']:,.0f} |\n",
        "                    <strong>Segment:</strong> #{profile['segment']}</p>\n",
        "                    <p><strong>Recommended Action:</strong> {next_action}</p>\n",
        "                </div>\n",
        "                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "            # Campaign summary\n",
        "            total_clv = sum(p['lifetime_value'] for _, p in target_customers)\n",
        "            avg_churn = np.mean([p['churn_probability'] for _, p in target_customers])\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Target Customers\", len(target_customers))\n",
        "            with col2:\n",
        "                st.metric(\"Total CLV\", f\"${total_clv:,.0f}\")\n",
        "            with col3:\n",
        "                st.metric(\"Avg Churn Risk\", f\"{avg_churn:.1%}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# PAGE 5: SETTINGS (API KEYS MOVED HERE)\n",
        "# ==============================================================================\n",
        "\n",
        "elif page == \"‚öôÔ∏è Settings\":\n",
        "    st.markdown(\"## ‚öôÔ∏è System Settings\")\n",
        "\n",
        "    st.markdown(\"### ü§ñ AI Configuration\")\n",
        "\n",
        "    st.info(\"\"\"\n",
        "    **OpenRouter API Keys Configuration**\n",
        "\n",
        "    The system supports up to 3 OpenRouter API keys for automatic rotation on rate limits or errors.\n",
        "    Get your free API keys from: **https://openrouter.ai/keys**\n",
        "\n",
        "    Configure your API keys below. Changes will be saved automatically.\n",
        "    \"\"\")\n",
        "\n",
        "    # API Key inputs with session state\n",
        "    api_key_1 = st.text_input(\n",
        "        \"API Key 1 (Primary)\",\n",
        "        type=\"password\",\n",
        "        value=st.session_state.api_key_1,\n",
        "        help=\"Primary API key for AI analysis\"\n",
        "    )\n",
        "\n",
        "    api_key_2 = st.text_input(\n",
        "        \"API Key 2 (Backup)\",\n",
        "        type=\"password\",\n",
        "        value=st.session_state.api_key_2,\n",
        "        help=\"Backup API key (optional)\"\n",
        "    )\n",
        "\n",
        "    api_key_3 = st.text_input(\n",
        "        \"API Key 3 (Backup)\",\n",
        "        type=\"password\",\n",
        "        value=st.session_state.api_key_3,\n",
        "        help=\"Second backup API key (optional)\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"üíæ Save API Keys\"):\n",
        "        st.session_state.api_key_1 = api_key_1\n",
        "        st.session_state.api_key_2 = api_key_2\n",
        "        st.session_state.api_key_3 = api_key_3\n",
        "        st.success(\"‚úÖ API Keys saved! They will be used in the next analysis run.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Model information\n",
        "    model_info = st.expander(\"üìã Available AI Models (Automatic Fallback)\", expanded=False)\n",
        "    with model_info:\n",
        "        st.markdown(\"\"\"\n",
        "        The system uses the following free models with automatic fallback:\n",
        "\n",
        "        1. **meta-llama/llama-3.2-3b-instruct:free** - Primary (Fast and efficient)\n",
        "        2. **google/gemini-flash-1.5:free** - Fallback 1 (Google's model)\n",
        "        3. **nousresearch/hermes-3-llama-3.1-405b:free** - Fallback 2 (Powerful model)\n",
        "\n",
        "        Models are automatically rotated if one fails or hits rate limits.\n",
        "        Each customer AI analysis includes 3 retry attempts before falling back to rule-based strategy.\n",
        "        \"\"\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### üìä Data Configuration\")\n",
        "\n",
        "    segment_count = st.slider(\"Number of Micro-Segments\", 5, 50, 20)\n",
        "    st.info(f\"System will create {segment_count} customer micro-segments for detailed analysis\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### üîÑ System Actions\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"üóëÔ∏è Clear AI Strategies Cache\"):\n",
        "            st.session_state.ai_strategies = {}\n",
        "            st.success(f\"‚úÖ Cleared {len(st.session_state.ai_strategies)} AI strategies from cache\")\n",
        "            st.rerun()\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"üîÑ Reset Engine\"):\n",
        "            st.session_state.engine = None\n",
        "            st.session_state.analysis_complete = False\n",
        "            st.session_state.results = None\n",
        "            st.session_state.ai_strategies = {}\n",
        "            st.success(\"‚úÖ Engine reset. Please re-run analysis from Dashboard.\")\n",
        "            st.rerun()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### üì• Export Options\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"üì• Export Customer Profiles\"):\n",
        "            if st.session_state.engine:\n",
        "                # Create export data\n",
        "                export_data = []\n",
        "                for cid, profile in st.session_state.engine.customer_profiles.items():\n",
        "                    export_data.append({\n",
        "                        'Customer ID': cid,\n",
        "                        'Churn Risk': profile['churn_risk'],\n",
        "                        'Churn Probability': profile['churn_probability'],\n",
        "                        'CLV': profile['lifetime_value'],\n",
        "                        'Segment': profile['segment'],\n",
        "                        'Tenure': profile['features'].get('tenure', 'N/A'),\n",
        "                        'Monthly Charges': profile['features'].get('MonthlyCharges', 'N/A')\n",
        "                    })\n",
        "\n",
        "                df_export = pd.DataFrame(export_data)\n",
        "                csv = df_export.to_csv(index=False)\n",
        "\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=f\"customer_profiles_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                    mime=\"text/csv\"\n",
        "                )\n",
        "            else:\n",
        "                st.warning(\"‚ö†Ô∏è No data to export. Please run analysis first.\")\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"üì• Export AI Strategies\"):\n",
        "            if st.session_state.ai_strategies:\n",
        "                # Convert to JSON\n",
        "                json_data = json.dumps(st.session_state.ai_strategies, indent=2)\n",
        "\n",
        "                st.download_button(\n",
        "                    label=\"üì• Download JSON\",\n",
        "                    data=json_data,\n",
        "                    file_name=f\"ai_strategies_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "                    mime=\"application/json\"\n",
        "                )\n",
        "            else:\n",
        "                st.warning(\"‚ö†Ô∏è No AI strategies to export. Generate some first in Customer Intelligence page.\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### üìä Current System Stats\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        profiles_count = len(st.session_state.engine.customer_profiles) if st.session_state.engine else 0\n",
        "        st.metric(\"Customer Profiles\", profiles_count)\n",
        "\n",
        "    with col2:\n",
        "        ai_count = len(st.session_state.ai_strategies)\n",
        "        st.metric(\"AI Strategies Generated\", ai_count)\n",
        "\n",
        "    with col3:\n",
        "        api_keys_configured = sum(1 for k in [st.session_state.api_key_1, st.session_state.api_key_2, st.session_state.api_key_3] if k)\n",
        "        st.metric(\"API Keys Configured\", api_keys_configured)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### ‚ÑπÔ∏è About\")\n",
        "    st.info(\"\"\"\n",
        "    **AI-Driven Hyper-Personalization Platform**\n",
        "\n",
        "    Version: 2.0.0\n",
        "\n",
        "    This platform uses AI agents to create individual customer intelligence profiles\n",
        "    and generate personalized strategies on-demand with automatic retry logic.\n",
        "\n",
        "    **Key Features:**\n",
        "    - Individual customer profiling (not personas)\n",
        "    - On-demand AI-powered action generation\n",
        "    - Automatic retry logic (3 attempts per customer)\n",
        "    - API key rotation for reliability\n",
        "    - Real-time propensity scoring\n",
        "    - Proactive churn prevention\n",
        "    - Personalized campaign generation\n",
        "\n",
        "    **What's New in v2.0:**\n",
        "    - Changed from \"Analyze top N\" to on-demand AI generation per customer\n",
        "    - Added retry logic for robust AI response generation\n",
        "    - API keys configuration moved to Settings page\n",
        "    - Improved customer intelligence interface with AI action buttons\n",
        "    - Added export functionality for profiles and strategies\n",
        "    - Enhanced dashboard with all original visualizations\n",
        "    \"\"\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; color: #666; padding: 2rem;'>\n",
        "    <p>ü§ñ <strong>AI-Driven Hyper-Personalization & Churn Intelligence Platform</strong></p>\n",
        "    <p>Individual-Centric Intelligence ‚Ä¢ On-Demand AI Actions ‚Ä¢ Automatic Retry Logic</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk8hCIkFkhNO",
        "outputId": "4ad3facb-9ec0-42f5-b7fe-a5970b7cf4f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2ubujdtAi5h5JKYCfAm28KXigdg_67UvKVFpECE1opeu34gbP\")\n",
        "def run_streamlit():\n",
        "  os.system('streamlit run /content/app.py --server.port 8000')\n",
        "import os\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"2ubujdtAi5h5JKYCfAm28KXigdg_67UvKVFpECE1opeu34gbP\")\n",
        "!ngrok config add-authtoken'2ubujdtAi5h5JKYCfAm28KXigdg_67UvKVFpECE1opeu34gbP'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_famLdKFkdxq",
        "outputId": "748b9456-8991-4225-9f2e-87ccd218729d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME:\n",
            "  config - update or migrate ngrok's configuration file\n",
            "\n",
            "USAGE:\n",
            "  ngrok config [flags]\n",
            "\n",
            "DESCRIPTION: \n",
            "  The config command gives a quick way to create or update ngrok's configuration\n",
            "  file. Use 'add-authtoken' or 'add-api-key' to set the corresponding properties.\n",
            "\n",
            "  Use 'check' to test a configuration file for validity. If you have an old\n",
            "  configuration file, you can also use 'upgrade' to automatically migrate to the\n",
            "  latest version.\n",
            "\n",
            "COMMANDS:\n",
            "  add-api-key                    save api key to configuration file\n",
            "  add-authtoken                  save authtoken to configuration file\n",
            "  add-connect-url                adds the connect URL (connect_url) to configuration file for custom agent ingress\n",
            "  add-server-addr                alias of add-connect-url\n",
            "  check                          check configuration file\n",
            "  edit                           edit configuration file\n",
            "  upgrade                        auto-upgrade configuration file\n",
            "\n",
            "OPTIONS:\n",
            "      --config strings   path to config files; they are merged if multiple\n",
            "  -h, --help             help for config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eENEcXZkcbw",
        "outputId": "bf2b91d6-d107-4c03-b883-690a10f62908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://a1990807f79c.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ],
      "source": [
        "thread=Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "public_url = ngrok.connect(addr='8000' ,proto='http',bind_tls=True)\n",
        "print(public_url)"
      ]
    }
  ]
}